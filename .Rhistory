message_str
})
twitter_search <- observeEvent(
input$search, {
tweet_gettr(input$username)
}
)
output$sentence <- renderText({
input$make_sentence
make_sentence(twitter_search)
})
}
runApp()
runApp()
runApp()
runApp()
# The UI is the result of calling the `fluidPage()` layout function
my_ui <- fluidPage(
# A static content element: a 2nd level header that displays text
h2("mRkov: A fun toolbox"),
# A widget: a text input box (save input in the `username` key)
textInput(inputId = "username", label = "Insert Twitter handle (@)"),
# a button to activate a twitter search
actionButton(inputId = "search", label = "Search Twitter!"),
actionButton(inputId = "make_sentence", label = "Make a Sentence!"),
# An output element: a text output (for the `message` key)
textOutput(outputId = "message"),
# An output element: a text output (for the `message` key)
textOutput(outputId = "sentence")
)
runApp()
runApp()
runApp()
runApp()
runApp()
e
source("my_server.R")
# To start running your app, pass the variables defined in previous
# code snippets into the `shinyApp()` function
shinyApp(ui = my_ui, server = my_server)
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
library(devtools)
install("../mRkov")
runApp()
runApp()
shiny::runApp()
runApp()
?twitteR
?tweet_gettr
?make_sentence
library(dplyy)
library(dplyr)
library(mRkov)
data("tweets")
make_wordcloud <- function(information, stops = "") {
if (is.null(information)) {
return(NULL)
}
information <- information$tokens
information <- information %>%
dplyr::group_by(lowercase_tokens) %>%
dplyr::summarise(n = n()) %>%
dplyr::arrange(-n)
stopwords <- stopwords::data_stopwords_smart$en
stopwords <- c(stopwords, stops, "endofline")
stopwords <- data.frame(stopwords, stringsAsFactors = F)
information <- dplyr::anti_join(information, stopwords, by= c("lowercase_tokens" = "stopwords"))
wordcloud::wordcloud(information$lowercase_tokens, information$n)
}
make_wordcloud(tweets)
make_wordcloud <- function(information, stops = "") {
if (is.null(information)) {
return(NULL)
}
information <- information$tokens
information <- information %>%
count()
stopwords <- stopwords::data_stopwords_smart$en
stopwords <- c(stopwords, stops, "endofline")
stopwords <- data.frame(stopwords, stringsAsFactors = F)
information <- dplyr::anti_join(information, stopwords, by= c("lowercase_tokens" = "stopwords"))
wordcloud::wordcloud(information$lowercase_tokens, information$n)
}
make_wordcloud(tweets)
make_wordcloud(tweets)
print(count)
make_wordcloud <- function(information, stops = "") {
if (is.null(information)) {
return(NULL)
}
information <- information$tokens
information <- information %>%
count()
print(count)
stopwords <- stopwords::data_stopwords_smart$en
stopwords <- c(stopwords, stops, "endofline")
stopwords <- data.frame(stopwords, stringsAsFactors = F)
information <- dplyr::anti_join(information, stopwords, by= c("lowercase_tokens" = "stopwords"))
wordcloud::wordcloud(information$lowercase_tokens, information$n)
}
make_wordcloud <- function(information, stops = "") {
if (is.null(information)) {
return(NULL)
}
information <- information$tokens
information <- information %>%
count()
print(information)
stopwords <- stopwords::data_stopwords_smart$en
stopwords <- c(stopwords, stops, "endofline")
stopwords <- data.frame(stopwords, stringsAsFactors = F)
information <- dplyr::anti_join(information, stopwords, by= c("lowercase_tokens" = "stopwords"))
wordcloud::wordcloud(information$lowercase_tokens, information$n)
}
make_wordcloud(tweets)
information <- information %>%
count(lowercase_tokens, sort =T)
make_wordcloud <- function(information, stops = "") {
if (is.null(information)) {
return(NULL)
}
information <- information$tokens
information <- information %>%
count(lowercase_tokens, sort =T)
stopwords <- stopwords::data_stopwords_smart$en
stopwords <- c(stopwords, stops, "endofline")
stopwords <- data.frame(stopwords, stringsAsFactors = F)
information <- dplyr::anti_join(information, stopwords, by= c("lowercase_tokens" = "stopwords"))
wordcloud::wordcloud(information$lowercase_tokens, information$n)
}
make_wordcloud(tweets)
devtools::check()
library(mRkov)
devtools::document()
library(mRkov)
devtools::document()
install.packages("magrittr")
install.packages("magrittr")
devtools::document()
library(mRkov)
library(mRkov)
library(mRkov)
devtools::document()
library(mRkov)
devtools::document()
library(mRkov)
data("trump_tweets")
make_sentence(data("trump_tweets"))
make_sentence(data(trump_tweets))
class(trump_tweets)
make_sentence(trump_tweets)
make_sentence(trump_tweets)
make_sentence(trump_tweets)
devtools::document()
library(mRkov)
devtools::document()
library(mRkov)
?make_sentence
devtools::document()
library(mRkov)
?make_sentence
class(data("trump_tweets"))
print(data("trump_tweets"))
library(mRkov)
?make_sentence
devtools::document()
library(mRkov)
?make_sentence
library(roxygen2)
devtools::document()
library(mRkov)
?make_sentence
library(roxygen2)
library(devtools)
document()
library(mRkov)
?make_sentence
library(devtools)
library(roxygen2)
document()
library(mRkov)
?read_text_file
library(roxygen2)
library(devtools)
document()
library(mRkov)
?make_sentence
libar
library(roxygen2)
library(dev)
library(devtools)
document()
?make_sentence
library(mRkov)
?make_sente
?make_sentence
library(roxygen2)
devtools::document()
library(mRkov)
setup_twitteR()
z <- tweet_gettr("@zgmatson")
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
View(z)
View(z)
View(z$tokens)
setup_twitteR()
z <- tweet_gettr("@zgmatson")
make_sentence(z)
library(mRkov)
setup_twitteR()
z <- tweet_gettr("@zgmatson")
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
z <- tweet_gettr("@realdonaldtrump")
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
z <- tweet_gettr("@realdonaldtrump")
make_sentence(z)
make_sentence(z)
make_sentence(z, n = 50)
make_sentence(z, n = 50)
make_sentence(z, n = 50)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
library(mRkov)
z <- tweet_gettr("@realdonaldtrump")
setup_twitteR()
z <- tweet_gettr("@realdonaldtrump")
View(z)
View(z$tokens)
make_sentence(z, prompt = "won't")
make_sentence(z, prompt = "won't")
make_sentence(z, prompt = "do")
make_sentence(z, prompt = "spied")
make_sentence(z, prompt = "spied")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "which")
z <- tweet_gettr("@zgmatson")
z <- tweet_gettr("@zgmatson")
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
make_sentence(z)
z <- tweet_gettr("@zgmatson")
make_sentence(z, prompt = "which")
make_sentence(z, prompt = "spied")
make_sentence(z, prompt = "do")
make_sentence(z, prompt = "won't")
library(mRkov)
library(mRkov)
library(mRkov)
setup_twitteR()
tho <- tweet_gettr("@thebreadfarm")
for (1:30) {print(make_sentence(tho))}
for (x in 1:30) {print(make_sentence(tho))}
for (x in 1:50) {print(make_sentence(tho))}
library(mRkov)
for (x in 1:50) {print(make_sentence(tho))}
for (x in 1:50) {print(make_sentence(tho))}
for (x in 1:50) {print(make_sentence(tho))}
for (x in 1:50) {print(make_sentence(tho, prompt = "karate"))}
View(tho)
View(tho$tokens)
library(mRkov)
setup_twitteR()
tweet_gettr("@thebreadfarm")
library(mRkov)
setup_twitteR()
tweet_gettr("@thebreadfarm")
library(mRkov)
tweet_gettr("@thebreadfarm")
setup_twitteR()
tweet_gettr("@thebreadfarm")
View(tho)
View(tho$tokens)
library(mRkov)
setup_twitteR()
tweet_gettr("@thebreadfarm")
tho <-tweet_gettr("@thebreadfarm")
View(tho$tokens)
for (x in 1:50) {print(make_sentence(tho, prompt = "karate"))}
?wordcloud::wordcloud
library(mRkov)
make_wordcloud(tho)
make_wordcloud(tho, n = 3)
make_wordcloud(tho, n = 7)
make_wordcloud(tho, n = 10)
make_wordcloud(tho, n = 20)
library(mRkov)
make_wordcloud(tho, n = 20)
make_wordcloud(tho)
library(mRkov)
library(mRkov)
library(mRkov)
setup_twitteR()
t <- tweet_gettr("@thebreadfarm")
View(t)
View(t$tokens)
View(t)
t <- tweet_gettr("@realdonaldtrump")
View(t)
View(t$handles)
library(mRkov)
library(mRkov)
document*()
document()
library(roxygen2)
library(devtools)
document()
library(mRkov)
?make_wordcloud
library(mRkov)
setup_twitteR()
tweet_gettr("@realdonaldtrump")
library(mRkov)
library(mRkov)
setup_twitteR()
tweet_gettr("@realdonaldtrump")
library(mRkov)
setup_twitteR()
asdf <- tweet_gettr("@realdonaldtrump")
View(asdf$text)
View(asdf$tokens)
View(c("\n"))
library(mRkov)
gsub("(\\b @ \\b+)","@", "text_lines @ asdlfkalsd")
gsub("(\\b @ \\b+)","@", "text_lines  @ asdlfkalsd")
gsub("( @ +)","@", "text_lines  @ asdlfkalsd")
library(mRkov)
setup_twitteR()
asdf <- tweet_gettr("@realdonaldtrump")
View(asdf)
shiny::runApp('../mRkov_shiny')
runApp('../mRkov_shiny')
runApp()
runApp('../mRkov_shiny')
asdf <- 1:20
asdf[1:5]
library(mRkov)
setup_twitteR()
asdf <- tweet_gettr("@realdonaldtrump")
make_sentence(asdf, prompt = "#")
View(asdf$tokens)
# %in% asdf$tokens$firsts[asdf$tokens$firsts]
"#" %in% asdf$tokens$firsts[asdf$tokens$firsts]
regex_prompt <- paste('\\b', "#", '\\b', sep = "")
corpus <- asdf$tokens
prompt_is_valid <- grepl(regex_prompt, corpus$lowercase_tokens, ignore.case = T)
any(prompt_is_valid)
"#" %in% corpus$lowercase_tokens
"thank" %in% corpus$lowercase_tokens
?grep
prompt_is_valid <- grepl(regex_prompt, corpus$lowercase_tokens, ignore.case = T)
any(prompt_is_valid)
corpus$lowercase_tokens[prompt_is_valid]
prompt_is_valid <- grepl("#", corpus$lowercase_tokens, ignore.case = T)
corpus$lowercase_tokens[prompt_is_valid]
prompt_is_valid <- grepl("#{1}.{0}", corpus$lowercase_tokens, ignore.case = T)
corpus$lowercase_tokens[prompt_is_valid]
prompt_is_valid <- grepl("^#$", corpus$lowercase_tokens, ignore.case = T)
corpus$lowercase_tokens[prompt_is_valid]
any(prompt_is_valid)
prompt_is_valid <- grepl("^#prayfornashville$", corpus$lowercase_tokens, ignore.case = T)
any(prompt_is_valid)
corpus$lowercase_tokens[prompt_is_valid]
prompt_is_valid <- grepl("^thank$", corpus$lowercase_tokens, ignore.case = T)
corpus$lowercase_tokens[prompt_is_valid]
make_sentence(asdf, "@me")
make_sentence(asdf, "@me")
make_sentence(asdf, "@")
make_sentence(asdf, "@")
make_sentence(asdf, "@")
make_sentence(asdf, "@")
make_sentence(asdf, "@")
make_sentence(asdf, "@")
make_sentence(asdf, "@")
make_sentence(asdf, "@")
make_sentence(asdf, "@")
library(mRkov)
install.packages("rtweet")
install.packages("rtweet")
api_key <- "23YB5C8ywbEP9tkjzADC3u1fx"
api_secret <- "SwWlFEk2DDaSjOezkcFi5b9HhR0eIicqB1kPJLgLNZOI8V6KDk"
token <- "1223331636856573952-xGkEYLfx5oe9VxD9abTllVpUax6YQe"
token_secret <- "A0ijbzOkW3uYUQAIy24sFP7Qbp3nM8Of2sSg4L7cPgSvi"
rtweet::create_token(api_key, api_secret, token, token_secret)
return(rtweet::create_token(app="placeholder",api_key, api_secret, token, token_secret))
rtweet::create_token(app="placeholder",api_key, api_secret, token, token_secret)
library(mRkov)
devtools::document()
library(mRkov)
library(mRkov)
shiny::runApp('../mRkov_shiny')
library(mRkov)
token <- setup_twitteR()
asdf <- tweet_gettr("@realdonaldtrump", token = token)
debug(tweet_gettr)
asdf <- tweet_gettr("@realdonaldtrump", token = token)
handle
asdf <- "@adsfjhasdlf"
substr(asdf, 2, length(asdf))
?substr
substr(asdf, 2, str_length(asdf))
substr(asdf, 2, stringr::str_length(asdf))
library(mRkov)
debug(tweet_gettr)
token <- setup_twitteR()
asdf <- tweet_gettr("@realdonaldtrump")
asdf <- tweet_gettr("@realdonaldtrump")
library(mRkov)
runApp('../mRkov_shiny')
library(mRkov)
library(mRkov)
shiny::runApp('../mRkov_shiny')
runApp()
runApp('../mRkov_shiny')
runApp('../mRkov_shiny')
gsub("([\\.?,!]+)"," \\1 ", "text_lines>?!.,")
gsub("([\\.?,!])+"," \\1 ", "text_lines>?!.,")
gsub("([\\.?,!]+)+"," \\1 ", "text_lines>?!.,")
gsub("([\\.?,!])+"," \\1 ", "text_lines>?!.,")
gsub("([\\.|?|,|!])+"," \\1 ", "text_lines>?!.,")
gsub("([\\.|?|,|!]+)"," \\1 ", "text_lines>?!.,")
gsub("([\\.|\\?|\\,|\\!]+)"," \\1 ", "text_lines>?!.,")
gsub("[\\.|\\?|\\,|\\!]"," \\1 ", "text_lines>?!.,")
gsub("([\\.|\\?|\\,|\\!])"," \\1 ", "text_lines>?!.,")
library(mRkov)
library(mRkov)
